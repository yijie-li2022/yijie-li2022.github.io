<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Yijie Li</title>
    <link>https://yijie-li2022.github.io/project/</link>
      <atom:link href="https://yijie-li2022.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 27 Apr 2016 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yijie-li2022.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://yijie-li2022.github.io/project/</link>
    </image>
    
    <item>
      <title>A Simple Deep Learning System</title>
      <link>https://yijie-li2022.github.io/project/simple-deeplearning-system/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://yijie-li2022.github.io/project/simple-deeplearning-system/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This is a simple deep learning system with numpy. It include a &lt;code&gt;autograd&lt;/code&gt; system which is the basis of the whole system while all network layers and tensor
operations that implemented are based on the simple dynamic computation graph. We now support fundamental mathmatics operation and several layers, including &lt;code&gt;Linear&lt;/code&gt;, 
&lt;code&gt;ReLU&lt;/code&gt;, &lt;code&gt;Dropout1d&lt;/code&gt;, &lt;code&gt;BatchNorm1d&lt;/code&gt;, &lt;code&gt;Softmax&lt;/code&gt;, and some pre-defined loss functions such as &lt;code&gt;MSELoss&lt;/code&gt; and &lt;code&gt;CrossEntropyLoss&lt;/code&gt;. We plan to support some core components of 
convolution nerual networks and CUDA in the future.&lt;/p&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick Start&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Download MNIST dataset and place it in ./dataset/mnist,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;then it should satisfy the structure below&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├─dataset
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    └─mnist
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ├─ source.txt
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ├─ t10k-images.idx3-ubyte
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ├─ t10k-labels.idx1-ubyte
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ├─ train-images.idx3-ubyte
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        └─ train-labels.idx1-ubyte
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run example of linear regression&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python ex_linear_regression.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run example of MLP on MNIST dataset&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python ex_mlp_mnist.py
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;```x_mlp_mnist.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>PaddlePaddle Reproduction of DDPM</title>
      <link>https://yijie-li2022.github.io/project/paddlepaddle-ddpm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://yijie-li2022.github.io/project/paddlepaddle-ddpm/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This is a PaddlePaddle reproduction of Denoising Diffusion Probabilistic Models (DDPM) and Denoising Diffusion Implicit Models (DDIM). We trained the diffusion model with original-designed UNet on CIFAR10 (32X32) and simplified verison (FPN, according to &lt;a href=&#34;https://github.com/bojone/Keras-DDPM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Keras-DDPM&lt;/a&gt;) on CelebA-HQ (128X128).&lt;/p&gt;
&lt;div style=&#39;color: red&#39;&gt;Warning: We don&#39;t recommend you to use the CIFAR10 training script of this repo, because it may have some bugs which may lead to a low FID, and we will try to fix this problem in the future.&lt;/div&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick Start&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Download pretrained weights and place in folder &lt;code&gt;ckpt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://pan.baidu.com/s/1VV7IH0mXzIwtCFXlCers7w?pwd=tew7&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Baidu Yun&lt;/a&gt;, password: &lt;code&gt;tew7&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use pretrained weights to do the generation (DDPM)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python run_cifar10.py --pretrained_path &amp;#39;./ckpts/ddpm_cifar10_i800000_ema.pdparam&amp;#39; --num_images &amp;#39;400-20-20&amp;#39; --mode &amp;#39;denoise&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use pretrained weights to do the generation (DDIM)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python run_celeba_hq_ddim.py --pretrained_path &amp;#39;./ckpts/ddpm_cifar10_i1000000_ema.pdparam&amp;#39; --num_images &amp;#39;64-8-8&amp;#39; --batchsize 64
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
